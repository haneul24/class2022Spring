{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "huggingface_gradio.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOFb0Ocj8dsEQWYTphgn58h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsnam95/class2022Spring/blob/main/huggingface_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIc3wBXqPoAi"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Image classification](https://huggingface.co/tasks/image-classification)"
      ],
      "metadata": {
        "id": "HiGiIwHHXyJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/google/vit-base-patch16-224 \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "N85f15SRXtON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "gJatB6PFZdse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "# model predicts one of the 1000 ImageNet classes\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "id": "ldZauC4yXfBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "CR7IwXS5Ybbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func (image):\n",
        "  feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "  model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "  inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "  outputs = model(**inputs)\n",
        "  logits = outputs.logits\n",
        "  # model predicts one of the 1000 ImageNet classes\n",
        "  predicted_class_idx = logits.argmax(-1).item()\n",
        "  predicted_class = model.config.id2label[predicted_class_idx]\n",
        "  return predicted_class"
      ],
      "metadata": {
        "id": "CA35L2ZPZveq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/tiger.jpg\"\n",
        "os.system(\"curl \" + url + \" > tiger.jpg\")\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/dog.jpg\"\n",
        "os.system(\"curl \" + url + \" > dog.jpg\")"
      ],
      "metadata": {
        "id": "v4FSg0gMbBLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='image', outputs='text', examples = ['tiger.jpg', 'dog.jpg']).launch()"
      ],
      "metadata": {
        "id": "h3N3dCkG2o3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Fill-Mask](https://huggingface.co/tasks/fill-mask)"
      ],
      "metadata": {
        "id": "Z8kY0va6YuS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/bert-base-uncased \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "IGD_q0SXfCF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "zR23S_FtfIkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "unmasker(\"Hello I'm a [MASK] model.\")"
      ],
      "metadata": {
        "id": "spM_LYGees_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "KaobDkL0fRJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def func (text):\n",
        "  unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "  result = unmasker(text)\n",
        "  df = pd.DataFrame(result)\n",
        "  return df"
      ],
      "metadata": {
        "id": "3CKQl_oDfTsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\"Hello I'm a [MASK] model.\", \"It is raining outside. I feel [MASK].\"]"
      ],
      "metadata": {
        "id": "-OkQDYW2wju6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe', examples = examples).launch()"
      ],
      "metadata": {
        "id": "1aGFWiTUfl9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Token classification](https://huggingface.co/tasks/token-classification)"
      ],
      "metadata": {
        "id": "0DDckwQ50cRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/dslim/bert-base-NER \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "mxv4tEUM0y_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "hUVn8h1304DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."
      ],
      "metadata": {
        "id": "9ksySb1Q50wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "example = \"My name is Wolfgang and I live in Berlin\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)"
      ],
      "metadata": {
        "id": "d9UOCPGJ0b1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "1CuE0WLi0x7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "def func (text):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "  model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "  nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "  result = nlp(text)\n",
        "  df = pd.DataFrame(result)\n",
        "  return df"
      ],
      "metadata": {
        "id": "jlx5iyV_0xV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\"My name is Wolfgang and I live in Berlin\", \"I will visit Seoul to see Chris\"]"
      ],
      "metadata": {
        "id": "upMTUXmc4fip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe', examples = examples).launch()"
      ],
      "metadata": {
        "id": "Nes4r_Ek4fYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Sentence similarity](https://huggingface.co/tasks/sentence-similarity)"
      ],
      "metadata": {
        "id": "dE0umBRo7knv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "WJByl36a7lbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "lZvWkGmwAasZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sentences = [\"This is an example sentence\", \"it is one example writing\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "ahXHjR-x7nP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[1])"
      ],
      "metadata": {
        "id": "z9tLd396Hthr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_scores = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "cosine_scores"
      ],
      "metadata": {
        "id": "Ne5AH2qbCZy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "As33TUuTcJH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func (text1, text2):\n",
        "  from sentence_transformers import SentenceTransformer, util\n",
        "  model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "  embeddings = model.encode([text1, text2])\n",
        "  cosine_scores = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "  return cosine_scores"
      ],
      "metadata": {
        "id": "XqwC0HHicM71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [[\"This is an example sentence\", \"it is one example writing\"], [\"A frog is hopping near the pond\", \"I love Korean Food\"]]"
      ],
      "metadata": {
        "id": "zZMVURDWcTNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs=['text', 'text'], outputs='number', examples = examples).launch()"
      ],
      "metadata": {
        "id": "1pbOXexycTGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image segmentation"
      ],
      "metadata": {
        "id": "WJVDtosTDDLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install timm # may need to restart runtime"
      ],
      "metadata": {
        "id": "QF5ppCQ9DkIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DetrFeatureExtractor, DetrForSegmentation\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "feature_extractor = DetrFeatureExtractor.from_pretrained('facebook/detr-resnet-50-panoptic')\n",
        "model = DetrForSegmentation.from_pretrained('facebook/detr-resnet-50-panoptic')\n",
        "\n",
        "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "# model predicts COCO classes, bounding boxes, and masks\n",
        "logits = outputs.logits\n",
        "bboxes = outputs.pred_boxes\n",
        "masks = outputs.pred_masks\n"
      ],
      "metadata": {
        "id": "l-2z6YW5DKTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bboxes"
      ],
      "metadata": {
        "id": "WvV--ug5EMyn",
        "outputId": "25ed6a13-3c08-4c15-8f95-dbafe8d5d874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.5344, 0.1789, 0.9285, 0.1212],\n",
              "         [0.4420, 0.0572, 0.0875, 0.0377],\n",
              "         [0.6630, 0.6887, 0.1017, 0.0764],\n",
              "         [0.3425, 0.5202, 0.6624, 0.8324],\n",
              "         [0.7803, 0.6495, 0.0983, 0.1044],\n",
              "         [0.0871, 0.0121, 0.1741, 0.0243],\n",
              "         [0.3126, 0.5251, 0.6031, 0.7939],\n",
              "         [0.3199, 0.1667, 0.0605, 0.0680],\n",
              "         [0.0063, 0.7713, 0.0128, 0.3719],\n",
              "         [0.1772, 0.2073, 0.2082, 0.1265],\n",
              "         [0.5496, 0.3104, 0.0660, 0.2969],\n",
              "         [0.5000, 0.4987, 0.9985, 0.9976],\n",
              "         [0.2927, 0.4448, 0.5469, 0.6642],\n",
              "         [0.1796, 0.1944, 0.1999, 0.1038],\n",
              "         [0.7915, 0.6690, 0.0651, 0.0912],\n",
              "         [0.4999, 0.9573, 0.9982, 0.0807],\n",
              "         [0.6537, 0.4034, 0.6854, 0.7289],\n",
              "         [0.4058, 0.5151, 0.7853, 0.8796],\n",
              "         [0.5016, 0.5023, 0.9972, 0.8691],\n",
              "         [0.6117, 0.4471, 0.7704, 0.8251],\n",
              "         [0.5398, 0.2950, 0.0784, 0.2789],\n",
              "         [0.3478, 0.0058, 0.1421, 0.0121],\n",
              "         [0.4975, 0.2904, 0.1547, 0.2720],\n",
              "         [0.3298, 0.4549, 0.6493, 0.8865],\n",
              "         [0.9974, 0.7673, 0.0052, 0.2894],\n",
              "         [0.2654, 0.4312, 0.4677, 0.6339],\n",
              "         [0.4521, 0.2507, 0.0650, 0.1792],\n",
              "         [0.2747, 0.3148, 0.4266, 0.3501],\n",
              "         [0.9942, 0.2490, 0.0117, 0.1789],\n",
              "         [0.1773, 0.1982, 0.2269, 0.1184],\n",
              "         [0.7710, 0.4030, 0.4553, 0.7237],\n",
              "         [0.6547, 0.0193, 0.1294, 0.0385],\n",
              "         [0.5003, 0.0513, 0.9981, 0.1031],\n",
              "         [0.5005, 0.0023, 0.9956, 0.0046],\n",
              "         [0.0935, 0.2133, 0.0909, 0.1150],\n",
              "         [0.5831, 0.0017, 0.2444, 0.0035],\n",
              "         [0.5000, 0.4000, 0.9975, 0.7667],\n",
              "         [0.8732, 0.2216, 0.2526, 0.4416],\n",
              "         [0.1442, 0.7568, 0.0465, 0.0526],\n",
              "         [0.7766, 0.4998, 0.4477, 0.9760],\n",
              "         [0.9704, 0.1306, 0.0589, 0.0769],\n",
              "         [0.4999, 0.9813, 0.9984, 0.0331],\n",
              "         [0.5467, 0.3431, 0.0605, 0.3728],\n",
              "         [0.1695, 0.1951, 0.2135, 0.0985],\n",
              "         [0.7809, 0.0754, 0.4387, 0.1507],\n",
              "         [0.4999, 0.7170, 0.9975, 0.5626],\n",
              "         [0.8801, 0.1445, 0.2383, 0.1366],\n",
              "         [0.5487, 0.2713, 0.0524, 0.2390],\n",
              "         [0.5388, 0.2811, 0.0587, 0.2431],\n",
              "         [0.8666, 0.0587, 0.2643, 0.1175],\n",
              "         [0.0028, 0.4051, 0.0057, 0.3462],\n",
              "         [0.2227, 0.7402, 0.0684, 0.0464],\n",
              "         [0.8759, 0.0588, 0.2456, 0.1176],\n",
              "         [0.7658, 0.4093, 0.4668, 0.7981],\n",
              "         [0.4332, 0.4841, 0.8492, 0.8715],\n",
              "         [0.1782, 0.2009, 0.2276, 0.1215],\n",
              "         [0.8473, 0.5378, 0.0702, 0.1153],\n",
              "         [0.5493, 0.2795, 0.0601, 0.2231],\n",
              "         [0.4999, 0.9561, 0.9982, 0.0833],\n",
              "         [0.4999, 0.4933, 0.9970, 0.9832],\n",
              "         [0.1637, 0.4210, 0.2226, 0.5523],\n",
              "         [0.5433, 0.1908, 0.0584, 0.1007],\n",
              "         [0.5001, 0.2381, 0.9980, 0.4793],\n",
              "         [0.8999, 0.9646, 0.1985, 0.0673],\n",
              "         [0.7084, 0.3923, 0.5787, 0.7079],\n",
              "         [0.2614, 0.4284, 0.4871, 0.6487],\n",
              "         [0.7087, 0.0113, 0.5713, 0.0227],\n",
              "         [0.4999, 0.5150, 0.9975, 0.8362],\n",
              "         [0.7097, 0.4067, 0.5782, 0.7245],\n",
              "         [0.4999, 0.9425, 0.9981, 0.1108],\n",
              "         [0.1817, 0.7382, 0.0749, 0.0585],\n",
              "         [0.8717, 0.4760, 0.2559, 0.9344],\n",
              "         [0.0234, 0.6295, 0.0469, 0.6980],\n",
              "         [0.5112, 0.2944, 0.0621, 0.2537],\n",
              "         [0.2573, 0.5396, 0.4759, 0.8646],\n",
              "         [0.5004, 0.4239, 0.9976, 0.6662],\n",
              "         [0.7188, 0.4011, 0.5587, 0.7112],\n",
              "         [0.4999, 0.9508, 0.9982, 0.0940],\n",
              "         [0.5024, 0.5080, 0.9966, 0.9073],\n",
              "         [0.9445, 0.1656, 0.1105, 0.1047],\n",
              "         [0.5001, 0.9924, 0.9987, 0.0109],\n",
              "         [0.8717, 0.0814, 0.2543, 0.1629],\n",
              "         [0.5017, 0.5062, 0.9977, 0.8933],\n",
              "         [0.0136, 0.5219, 0.0276, 0.9171],\n",
              "         [0.5000, 0.8750, 0.9977, 0.2437],\n",
              "         [0.8180, 0.5069, 0.0598, 0.0942],\n",
              "         [0.1665, 0.9552, 0.3300, 0.0852],\n",
              "         [0.5444, 0.2825, 0.0645, 0.2440],\n",
              "         [0.7682, 0.4546, 0.4612, 0.8593],\n",
              "         [0.5829, 0.0157, 0.3502, 0.0318],\n",
              "         [0.2546, 0.4334, 0.4795, 0.6486],\n",
              "         [0.0036, 0.5522, 0.0073, 0.4127],\n",
              "         [0.2591, 0.4226, 0.4845, 0.6287],\n",
              "         [0.4999, 0.9729, 0.9984, 0.0494],\n",
              "         [0.0134, 0.6321, 0.0267, 0.2850],\n",
              "         [0.7713, 0.4610, 0.4556, 0.8815],\n",
              "         [0.0239, 0.9062, 0.0475, 0.1810],\n",
              "         [0.8782, 0.0737, 0.2414, 0.1473],\n",
              "         [0.9771, 0.5052, 0.0457, 0.8438],\n",
              "         [0.3738, 0.0039, 0.7219, 0.0080]]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}